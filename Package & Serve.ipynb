{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f0adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df ready. shape: (3000, 20)\n",
      "Columns (first 10): ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup']\n"
     ]
    }
   ],
   "source": [
    "# Cell 0 — reload df and do the minimal cleaning we already decided earlier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Load your CSV (use the same path you used before)\n",
    "df = pd.read_csv(r'C:\\Users\\allur\\OneDrive\\Desktop\\project\\customer_churn_sample_3000.csv')\n",
    "\n",
    "# 2) Convert TotalCharges to numeric and fill any NaNs from conversion\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
    "\n",
    "# 3) Drop non-predictive ID if present\n",
    "if 'customerID' in df.columns:\n",
    "    df.drop('customerID', axis=1, inplace=True)\n",
    "\n",
    "# 4) Trim whitespace in text columns\n",
    "for c in df.select_dtypes(include='object').columns:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# 5) Ensure target exists and is 0/1 (handle case-insensitive 'churn')\n",
    "churn_candidates = [c for c in df.columns if c.lower() == 'churn']\n",
    "assert churn_candidates, f\"Couldn't find a 'Churn' column. Available columns: {list(df.columns)}\"\n",
    "if churn_candidates[0] != 'Churn':\n",
    "    df.rename(columns={churn_candidates[0]:'Churn'}, inplace=True)\n",
    "\n",
    "if df['Churn'].dtype == 'object':\n",
    "    df['Churn'] = df['Churn'].map({'Yes':1, 'No':0}).astype(int)\n",
    "\n",
    "print(\"df ready. shape:\", df.shape)\n",
    "print(\"Columns (first 10):\", list(df.columns)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f180f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models present: {'lr': 'LogisticRegression', 'model': 'LogisticRegression'}\n",
      "'X_train' exists: True\n"
     ]
    }
   ],
   "source": [
    "# Cell A — memory check\n",
    "CANDIDATES = ['best_model','xgb','rf','lr','model']\n",
    "present = {n: type(globals()[n]).__name__ for n in CANDIDATES if n in globals()}\n",
    "print(\"Models present:\", present)\n",
    "print(\"'X_train' exists:\", 'X_train' in globals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c747097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline LogisticRegression trained; model + X_train ready \n",
      "X_train shape: (2400, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allur\\AppData\\Local\\Temp\\ipykernel_39192\\1907318939.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.03382754  1.74300849  0.84094077 ...  1.22075876 -0.44094495\n",
      " -0.4884222 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, num_cols] = scaler.fit_transform(X_train[num_cols])\n",
      "C:\\Users\\allur\\AppData\\Local\\Temp\\ipykernel_39192\\1907318939.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.72580844  1.74300849  0.03382754 -1.10562643  0.36616828  1.17328151\n",
      " -0.10860421 -1.48544442 -0.15608146  1.03084976  0.65103177  0.84094077\n",
      "  1.3631905   1.5530995  -1.43796717  0.84094077  0.69850902  1.17328151\n",
      " -0.86824019 -1.34301267  1.41066775 -0.77328569  0.03382754 -1.20058093\n",
      "  1.74300849 -1.24805818 -0.91571743 -0.72580844 -1.29553542  0.55607728\n",
      "  0.65103177 -1.34301267 -0.63085394  0.93589527 -0.72580844  1.458145\n",
      "  0.36616828 -1.01067193 -1.15310368 -0.63085394 -1.05814918  0.12878204\n",
      "  0.65103177 -0.2035587  -1.10562643  0.65103177 -1.05814918 -0.53589945\n",
      " -0.77328569 -0.2985132   0.22373653  1.74300849 -0.82076294 -0.77328569\n",
      "  1.69553125  1.26823601 -0.2035587  -0.4884222   0.79346352  1.12580426\n",
      " -0.01364971  0.41364553  1.648054   -0.01364971  0.84094077  0.12878204\n",
      " -0.3934677   0.69850902  1.458145    1.74300849 -0.2035587  -1.10562643\n",
      " -0.10860421 -0.67833119 -1.05814918  0.79346352 -0.34599045  0.03382754\n",
      "  0.46112278  0.88841802 -0.10860421 -0.86824019  1.458145   -1.53292167\n",
      " -0.96319468  0.41364553 -1.24805818 -0.25103595  1.74300849  1.17328151\n",
      " -0.10860421 -0.2035587   0.69850902 -0.10860421  0.22373653 -0.34599045\n",
      "  1.3631905  -0.53589945  1.22075876 -1.24805818  1.5530995  -0.3934677\n",
      " -0.25103595 -0.44094495 -0.67833119 -0.86824019 -0.44094495 -0.15608146\n",
      " -1.58039892 -1.24805818 -1.01067193  0.46112278  0.65103177 -1.39048992\n",
      " -1.01067193  0.17625929 -0.10860421  0.27121378  0.74598627 -0.44094495\n",
      "  1.648054   -0.53589945  1.3631905   1.41066775 -0.25103595 -0.63085394\n",
      "  0.31869103  1.22075876 -0.34599045  1.648054   -1.48544442 -1.58039892\n",
      " -0.77328569  0.74598627 -0.96319468  1.60057675  0.65103177 -0.3934677\n",
      " -0.25103595 -1.05814918 -1.01067193  0.41364553  1.31571326  0.79346352\n",
      "  1.458145    0.46112278  1.648054    0.93589527 -1.67535341  0.46112278\n",
      " -0.44094495 -0.01364971  1.07832701 -0.44094495  1.26823601 -0.3934677\n",
      " -0.2035587  -1.58039892  1.5530995   1.648054   -0.86824019  0.65103177\n",
      "  0.12878204 -0.34599045  1.03084976 -0.10860421 -1.67535341 -1.39048992\n",
      " -1.43796717  1.07832701  1.648054   -0.77328569  1.03084976 -0.96319468\n",
      "  0.74598627  0.22373653  0.31869103 -0.58337669  0.88841802 -0.63085394\n",
      " -1.24805818  1.74300849  0.88841802 -1.58039892 -0.15608146  0.88841802\n",
      "  1.31571326 -1.01067193  1.648054    1.5530995   0.60355452  1.648054\n",
      "  0.55607728 -1.10562643  1.50562225 -1.39048992  0.31869103  1.22075876\n",
      "  0.22373653  0.08130479  1.07832701 -0.25103595 -0.63085394 -0.4884222\n",
      "  1.26823601  0.79346352  1.12580426  1.31571326  0.84094077 -1.34301267\n",
      "  0.36616828 -0.72580844  1.5530995  -0.2985132  -1.48544442 -0.58337669\n",
      " -0.67833119  0.08130479  0.27121378  1.31571326  0.22373653  0.69850902\n",
      "  0.60355452 -1.62787617  0.36616828 -0.82076294 -0.63085394 -0.25103595\n",
      "  1.22075876 -0.63085394 -0.4884222  -0.91571743  0.50860003  0.88841802\n",
      " -1.39048992 -1.48544442  1.22075876  1.458145    0.41364553  0.98337251\n",
      "  1.5530995  -1.15310368 -1.58039892  1.648054   -1.29553542 -0.82076294\n",
      "  1.648054    0.60355452 -0.25103595  1.03084976 -0.91571743 -1.01067193\n",
      "  1.5530995  -1.48544442  1.69553125  1.03084976  0.65103177 -0.63085394\n",
      " -0.72580844 -0.67833119  1.60057675 -0.25103595  1.648054    1.22075876\n",
      "  0.03382754 -1.24805818  0.41364553 -1.58039892 -1.10562643 -0.91571743\n",
      "  1.22075876 -0.06112696  1.74300849 -0.58337669  0.08130479  1.12580426\n",
      "  1.648054    0.27121378  1.3631905  -1.20058093  1.22075876 -0.2035587\n",
      " -1.58039892 -0.01364971 -1.05814918  0.69850902  1.50562225 -1.15310368\n",
      "  0.79346352 -1.43796717 -0.25103595  0.36616828  1.17328151  1.26823601\n",
      " -1.53292167 -0.82076294  1.26823601  0.65103177  0.88841802 -1.29553542\n",
      " -1.53292167  1.12580426 -0.67833119  0.74598627  0.65103177  1.41066775\n",
      "  1.648054    1.74300849  1.458145   -1.39048992  0.03382754 -1.05814918\n",
      " -1.62787617  0.98337251  0.84094077 -1.20058093 -1.67535341 -0.34599045\n",
      "  1.22075876 -1.01067193  1.31571326  1.41066775 -0.77328569  1.41066775\n",
      "  0.17625929  0.22373653  1.648054    0.79346352 -0.34599045  1.17328151\n",
      " -0.2035587  -1.01067193  1.41066775 -1.24805818 -0.2035587  -0.44094495\n",
      " -0.91571743  1.50562225  0.88841802  0.41364553 -0.25103595  0.93589527\n",
      " -1.29553542 -0.2985132   0.84094077  1.31571326  0.60355452 -1.10562643\n",
      " -0.2985132  -0.86824019 -0.72580844 -1.58039892 -1.53292167 -0.44094495\n",
      "  1.458145    1.03084976 -1.29553542 -0.77328569  1.07832701 -0.4884222\n",
      " -0.06112696  1.3631905   0.93589527 -0.58337669  1.3631905   0.88841802\n",
      "  1.50562225 -1.05814918  0.36616828  0.46112278  1.5530995  -0.3934677\n",
      "  1.60057675 -0.77328569  0.31869103 -0.2035587   1.03084976  1.69553125\n",
      " -0.2985132   0.46112278 -1.29553542 -0.72580844  0.08130479 -0.2985132\n",
      "  0.55607728 -0.77328569 -0.53589945 -1.58039892 -1.48544442  1.648054\n",
      "  0.22373653  1.22075876  0.60355452 -1.20058093  1.07832701 -1.43796717\n",
      "  0.65103177 -0.2985132   0.12878204 -0.53589945 -1.01067193  0.03382754\n",
      " -1.15310368 -0.96319468  0.46112278  0.69850902  0.55607728 -1.24805818\n",
      "  1.648054    0.27121378 -0.77328569  0.79346352  0.46112278  0.17625929\n",
      "  1.41066775  0.69850902 -1.01067193  1.26823601  0.74598627  1.458145\n",
      "  1.60057675 -0.2035587  -0.96319468  1.648054   -0.96319468 -0.91571743\n",
      " -1.53292167 -0.77328569 -1.48544442 -1.34301267  0.36616828 -1.15310368\n",
      " -0.25103595 -0.63085394 -1.34301267 -0.63085394  1.41066775 -1.62787617\n",
      " -0.2985132   1.3631905  -1.53292167 -0.34599045  0.50860003  1.22075876\n",
      "  0.74598627  0.17625929 -0.4884222   1.41066775  1.07832701  1.74300849\n",
      "  0.50860003 -0.91571743  1.12580426  1.74300849  0.65103177 -0.01364971\n",
      "  1.31571326 -1.48544442  0.84094077 -0.77328569 -1.48544442 -0.67833119\n",
      "  1.07832701  0.98337251  0.79346352 -0.34599045  0.60355452 -1.05814918\n",
      " -0.82076294 -1.24805818  0.69850902  1.50562225 -0.06112696 -0.91571743\n",
      " -0.96319468  1.22075876  0.65103177 -1.29553542 -0.15608146  0.08130479\n",
      "  0.22373653  0.88841802 -0.15608146 -0.67833119  0.03382754  1.12580426\n",
      "  0.79346352  1.648054    0.12878204  0.74598627 -1.53292167  0.08130479\n",
      "  1.69553125  1.22075876 -1.43796717 -0.53589945 -1.29553542  1.3631905\n",
      "  0.12878204  0.93589527  1.69553125 -0.25103595 -0.3934677   0.65103177\n",
      "  0.31869103 -1.29553542 -1.01067193  0.74598627 -1.48544442 -0.63085394\n",
      "  0.60355452 -1.39048992 -1.62787617  1.17328151 -0.58337669  1.41066775\n",
      "  0.03382754 -0.01364971 -1.58039892 -0.34599045 -0.86824019 -1.62787617\n",
      " -1.62787617 -1.24805818 -0.96319468  0.27121378 -1.62787617  0.69850902\n",
      "  0.17625929 -1.62787617 -0.3934677  -1.20058093  0.03382754  1.458145\n",
      "  1.74300849  0.12878204 -1.48544442  1.648054    0.46112278 -0.96319468\n",
      " -0.72580844  1.41066775  1.74300849  1.5530995  -1.20058093  1.41066775\n",
      " -0.72580844  1.69553125  1.17328151 -0.58337669 -1.05814918  0.41364553\n",
      " -1.67535341  1.458145   -0.10860421  0.93589527  0.22373653 -1.62787617\n",
      "  0.17625929  0.41364553 -0.01364971  0.12878204  1.3631905  -0.3934677\n",
      "  0.69850902  1.07832701 -0.96319468  0.41364553  1.74300849 -0.67833119\n",
      "  0.93589527 -1.15310368  0.55607728 -0.34599045  1.648054    1.5530995\n",
      " -0.01364971 -0.34599045  1.22075876  1.07832701  1.07832701 -0.67833119\n",
      "  0.22373653 -0.3934677  -1.05814918 -1.29553542 -0.67833119 -0.34599045\n",
      " -1.62787617 -0.96319468  0.88841802 -1.10562643 -0.67833119  1.50562225\n",
      " -1.10562643 -0.86824019  1.22075876  0.12878204  0.36616828  1.648054  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:,  num_cols] = scaler.transform(X_test[num_cols])\n"
     ]
    }
   ],
   "source": [
    "# Cell B — quick baseline to restore model + X_train\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# 1) sanity: df must exist\n",
    "assert 'df' in globals(), \"DataFrame df not found. Re-run your cleaning cell(s).\"\n",
    "\n",
    "# 2) ensure target is numeric 0/1\n",
    "assert 'Churn' in df.columns, \"Expected a 'Churn' column.\"\n",
    "if df['Churn'].dtype == 'object':\n",
    "    df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0}).astype(int)\n",
    "\n",
    "# 3) one-hot encode remaining object columns (exclude target)\n",
    "obj_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "if 'Churn' in obj_cols:\n",
    "    obj_cols.remove('Churn')\n",
    "df_enc = pd.get_dummies(df, columns=obj_cols, drop_first=True)\n",
    "\n",
    "# 4) split\n",
    "X = df_enc.drop(columns=['Churn'])\n",
    "y = df_enc['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 5) optional scaling for common numeric columns (if present)\n",
    "num_cols = [c for c in ['tenure','MonthlyCharges','TotalCharges'] if c in X_train.columns]\n",
    "scaler = None\n",
    "if num_cols:\n",
    "    scaler = StandardScaler()\n",
    "    X_train.loc[:, num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "    X_test.loc[:,  num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# 6) train a quick baseline model\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# expose variables your save-cell expects\n",
    "model = lr  # your save-cell will find this\n",
    "print(\"Baseline LogisticRegression trained; model + X_train ready \")\n",
    "print(\"X_train shape:\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0adbf34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using trained model variable: lr\n",
      "Saved:\n",
      " - models/model_20250907_182632.pkl\n",
      " - models/scaler_20250907_182632.pkl\n",
      " - models/columns_20250907_182632.json\n"
     ]
    }
   ],
   "source": [
    "# === Sprint 5 · Cell 1: Save artifacts (model, scaler, feature schema) ===\n",
    "from pathlib import Path\n",
    "import joblib, json, time\n",
    "\n",
    "# 1) pick your trained model variable automatically\n",
    "CANDIDATES = ['best_model', 'xgb', 'rf', 'lr', 'model']\n",
    "model = None\n",
    "for name in CANDIDATES:\n",
    "    if name in globals():\n",
    "        model = globals()[name]\n",
    "        print(f\"Using trained model variable: {name}\")\n",
    "        break\n",
    "assert model is not None, f\"No trained model variable found. Expected one of: {CANDIDATES}\"\n",
    "\n",
    "# 2) get feature columns in the exact order used for training\n",
    "assert 'X_train' in globals(), \"X_train not found. Keep X_train in memory (with the final encoded columns) before saving artifacts.\"\n",
    "feature_columns = list(X_train.columns)\n",
    "\n",
    "# 3) optional scaler if you used one\n",
    "scaler_obj = globals().get('scaler', None)\n",
    "\n",
    "# 4) make models/ and build stamped filenames\n",
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_path  = f\"models/model_{stamp}.pkl\"\n",
    "scaler_path = f\"models/scaler_{stamp}.pkl\" if scaler_obj is not None else None\n",
    "schema_path = f\"models/columns_{stamp}.json\"\n",
    "\n",
    "# 5) save artifacts\n",
    "joblib.dump(model, model_path)\n",
    "if scaler_obj is not None:\n",
    "    joblib.dump(scaler_obj, scaler_path)\n",
    "\n",
    "schema = {\n",
    "    \"feature_columns\": feature_columns,\n",
    "    \"model_path\": model_path,\n",
    "    \"scaler_path\": scaler_path,\n",
    "    \"created_at\": stamp\n",
    "}\n",
    "with open(schema_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(schema, f, indent=2)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", model_path)\n",
    "if scaler_path: print(\" -\", scaler_path)\n",
    "print(\" -\", schema_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
